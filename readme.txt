<br>用于免入库直接分析linux日志文件的异常IP，比如高频访问蜘蛛，高频探漏洞URL的IP
<br>系统会按IP访问次数排序，几百次以上的都可以分析下他们行为。
<br>比如IP@404 次数多了，URL多为非你常见路径，该IP即为扫描网站漏洞的。
<br>比如IP次数很多，UA有网址或包含spider/bot/crawler等即为蜘蛛，python-requests人工野蜘蛛
<br>性能参考：1核1G服务器 分析76.59MB/404101条日志@执行耗时7.35秒耗内存12,945.10KB
<br>使用：PHP5.5+, 使用前同级文件夹下放置.log日志文件并修改代码中日志文件路径！
